var documenterSearchIndex = {"docs":
[{"location":"lime/#LIME","page":"Lime","title":"LIME","text":"","category":"section"},{"location":"lime/","page":"Lime","title":"Lime","text":"Because LIME is a \"Local Interpretable Model-agnostic Explanations\" (LIME) you can use it for any model. In addition to the model to be explained, you need a specific input x.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"For our example we use a pre-trained LeNet5 model (model.bson) and a data point of the MNIST dataset for x.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"using ExplainableAI\nusing Flux\nusing BSON\nusing JML_XAI_Project\nusing CSV\nusing DataFrames\nusing XAIBase\nusing Images\n\n#our input x\ndf = CSV.read(\"../MNIST_input_9.csv\", DataFrame)\nx = Matrix(df)\ny = 9\n\ninput = reshape(x, 28, 28, 1, :);\ninput_rgb = repeat(input, 1, 1, 3, 1)\n\n#our model\nmodel = BSON.load(\"../model.bson\", @__MODULE__)[:model]\n","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"Now we are using the XAIBase template to generate an explanaition","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"struct LIME{M} <: AbstractXAIMethod \n    model::M    \nend\n\nfunction (method::LIME)(input, output_selector::AbstractOutputSelector)\n    output = method.model(input)\n    output_selection = output_selector(output)\n\n    val = rand(size(input)...) #it doesn't implement LIME yet\n    extras = nothing  # TODO: optionally add additional information using a named tuple\n    return Explanation(val, output, output_selection, :MyMethod, :attribution, extras)\nend","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"In the next step we call the XAIBase's analyze function to compute the LIME explanation.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"analyzer = LIME(model)\nexpl = analyze(input, analyzer);","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"To visualize the explanaition we create a heatmap","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"using VisionHeatmaps\nheatmap(expl.val)","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"note: Note\nAs you can see, the heatmap is quite noisy. This is because the XAIBase tamplate is still generating a random output. We still have to implement the LIME algoithm. But if you want to have a first impression of the LIME code structure, have a look at our source code. ","category":"page"},{"location":"shap/#SHAP","page":"SHAP","title":"SHAP","text":"","category":"section"},{"location":"shap/","page":"SHAP","title":"SHAP","text":"...to be implemented","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = JML_XAI_Project","category":"page"},{"location":"#JML*XAI*Project-LIME-and-SHAP-for-Julia","page":"Home","title":"JMLXAIProject - LIME and SHAP for Julia","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package implements the explainable AI methods LIME and SHAP using XAIBase.jl. JMLXAIproject provides explanations for image and text input and is visualized as a heatmap.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To use the package please add the following code to your environment","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/e-strauss/JML_XAI_Project.jl\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Documentation for JMLXAIProject.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [JML_XAI_Project]","category":"page"},{"location":"#JML_XAI_Project.LIME","page":"Home","title":"JML_XAI_Project.LIME","text":"struct LIME{M} <: AbstractXAIMethod\n\nThe LIME (Local Interpretable Model-agnostic Explanations) struct is used to create an instance of the LIME method for explainable AI (XAI). This method provides local explanations for the predictions of any machine learning model by approximating the model's behavior in the vicinity of a specific input.\n\nFields\n\nmodel::M: The machine learning model to be explained. The model should be callable with an input to produce an output.\n\n\n\n\n\n","category":"type"},{"location":"#JML_XAI_Project.data_labels","page":"Home","title":"JML_XAI_Project.data_labels","text":"Generates perturbed versions of a given image by turning superpixels on or off,using a specified  segmentation map. It then predicts the class probabilities for these perturbed images using a provided  classifier function. The function returns a tuple containing the binary matrix of perturbed images (data)  and their corresponding prediction probabilities (labels). This is useful for techniques like LIME to  understand and explain model predictions locally.\n\n\n\n\n\n","category":"function"},{"location":"#JML_XAI_Project.default_segmentation_function-Tuple{String}","page":"Home","title":"JML_XAI_Project.default_segmentation_function","text":"return image segmantation function, if no function was passed originally based on Scikit-Image implementation julia adaptations:\n\nquickshift\n\npackage: ??? (docs: ???)\nexplaination: ???\npython packages can be used in julia, it's therefore possible to use the scikit-image library if desired\n\nslic\n\ncode: https://github.com/Cuda-Chen/SLIC.jl/tree/master (docs: NOT EVEN AN INOFFICIAL PACKAGE)\ncode seems to work, but spelling mistakes in the original and takes forever\nexplaination: https://cuda-chen.github.io/image%20processing/2020/07/29/slic-in-julia.html\n\nfelzenszwalb\n\npackage: ImageSegmentation (docs: https://juliaimages.org/v0.21/imagesegmentation/)\nexplaination: https://www.analyticsvidhya.com/blog/2021/05/image-segmentation-with-felzenszwalbs-algorithm/\n\ncomparision: https://scikit-image.org/docs/stable/autoexamples/segmentation/plotsegmentations.html\n\nArgs:     algotype: string, segmentation algorithm among the following:         'quickshift', 'slic', 'felzenszwalb'     targetparams: dict, algorithm parameters (valid model paramters         as define in Scikit-Image documentation)\n\n\n\n\n\n","category":"method"},{"location":"#JML_XAI_Project.euclidian_distance-Tuple{Any, Any}","page":"Home","title":"JML_XAI_Project.euclidian_distance","text":"calculates the euclidian distance between each column vector in input matrix A and the column vectors in input matrix B\n\nArgs:     A:  matrix (m,n)     B:  matrix (m,n) or (1,n) Returns:     distance: 1-d array of distances\n\n\n\n\n\n","category":"method"},{"location":"#JML_XAI_Project.explain_instance","page":"Home","title":"JML_XAI_Project.explain_instance","text":"Generates explanations for a prediction.\n\nFirst, we generate neighborhood data by randomly perturbing features from the instance (see __datainverse). We then learn locally weighted linear models on this neighborhood data to explain each of the classes in an interpretable way (see limebase.py).\n\nArgs:     image: 3 dimension RGB image. If this is only two dimensional,         we will assume it's a grayscale image and call gray2rgb.     classifierfn: classifier prediction probability function, which         takes a numpy array and outputs prediction probabilities.  For         ScikitClassifiers , this is classifier.predictproba.     labels: iterable with labels to be explained.     hidecolor: If not None, will hide superpixels with this color.         Otherwise, use the mean pixel color of the image.     toplabels: if not None, ignore labels and produce explanations for         the K labels with highest prediction probabilities, where K is         this parameter.     numfeatures: maximum number of features present in explanation     numsamples: size of the neighborhood to learn the linear model     batchsize: batch size for model predictions     distancemetric: the distance metric to use for weights.     modelregressor: sklearn regressor to use in explanation. Defaults     to Ridge regression in LimeBase. Must have modelregressor.coef_     and 'sampleweight' as a parameter to modelregressor.fit()     segmentationfn: SegmentationAlgorithm, wrapped skimage     segmentation function     randomseed: integer used as random seed for the segmentation         algorithm. If None, a random integer, between 0 and 1000,         will be generated using the internal random number generator.\n\nReturns:     An ImageExplanation object (see lime_image.py) with the corresponding     explanations.\n\n\n\n\n\n","category":"function"},{"location":"#JML_XAI_Project.explain_instance_with_data","page":"Home","title":"JML_XAI_Project.explain_instance_with_data","text":"Takes perturbed data, labels and distances, returns explanation.\n\nParameters\n\nneighborhood_data: perturbed data\nneighborhood_labels: corresponding perturbed labels. should have as many columns as the number of possible labels.\ndistances: distances to original data point.\nkernel_fn: (similiarity) kernel function that transforms an array of distances into an array of proximity values (floats)\nlabel: label for which we want an explanation\nnum_features: maximum number of features in explanation\nmodel_regressor: sklearn regressor to use in explanation. Defaults to Ridge regression if None. Must have modelregressor.coef and 'sampleweight' as a parameter to modelregressor.fit()\n\n\n\n\n\n","category":"function"},{"location":"#JML_XAI_Project.feature_selection-Tuple{Any, Any, Any}","page":"Home","title":"JML_XAI_Project.feature_selection","text":"feature_selection(X::Matrix, y::Vector, max_feat::Int) -> ReturnType\n\nSelects features for the model using LARS with Lasso [https://tibshirani.su.domains/ftp/lars.pdf] s.t. len(selectedfeatures) <= maxfeat Use LARS package: https://github.com/simonster/LARS.jl\n\nPython reference: nonzero = range(weighteddata.shape[1]) coefs = generatelarspath(X, y) for i in range(len(coefs.T) - 1, 0, -1):     nonzero = coefs.T[i].nonzero()[0]     if len(nonzero) <= numfeatures:         return nonzero\n\nParameters\n\nX: weighted feature\ny: weighted labels\n\nReturns\n\nindices of selected features\n\n\n\n\n\n","category":"method"},{"location":"#JML_XAI_Project.sample_data-Tuple{Any, Any}","page":"Home","title":"JML_XAI_Project.sample_data","text":"sample_data(x0::Vector, x0_pertubed::Vector, H, D, model)\n\nReturns the neighborhood_data (perturbed data, first element is the original data point) by sampling around x0  and evaluate the model to generate the corresponding perturbed labels.\n\nCitation from Paper [https://arxiv.org/pdf/1602.04938]: We sample instances around x0pertubed by drawing nonzero elements of x0pertubed uniformly at random (where the number of such draws is also uniformly sampled). We sample instances both in the vicinity of x0 and far away from x (measured by the distance metric).\n\nParameters\n\nx0: original input\nx0_pertubed: interpretable representation of original input\nH: interpretable representation mapping function, s.t. h(x0_pertubed) = x0\nD: distance metric which calculates the distance of two points in the origial, non-interpretable space\nmodel: model which works on the non-interpretable original input\n\nReturns\n\nneighborhood_data: sampled perturbed data (first element is x0_pertubed)\nneighborhood_labels: corresponding perturbed calculated by the model and mapping function H\ndistances: distances of each sampled point to original data point calculated using the distance metric D and mapping function H\n\n\n\n\n\n","category":"method"},{"location":"#JML_XAI_Project.train_ridge_regressor-Tuple{Any, Any}","page":"Home","title":"JML_XAI_Project.train_ridge_regressor","text":"trainridgeregressor(X::Matrix, y::Vector, weights::Vector)\n\nReturns the trained simplified linear model using ridge regression: model = Ridge(alpha=1, fitintercept=True, randomstate=self.randomstate) model.fit(X,y, sampleweight=weights) return model\n\n\n\n\n\n","category":"method"},{"location":"#JML_XAI_Project.weighted_data-Tuple{Any, Any, Any}","page":"Home","title":"JML_XAI_Project.weighted_data","text":"normalize_data(X::Matrix, y::Vector, weights::Vector)\n\nReturns the weight normalization of X (data) and y (label) using the weight vector y. Xnorm = ((X - np.average(X, axis=0, weights=weights)) * np.sqrt(weights[:, np.newaxis])) Ynorm = ((y - np.average(y, weights=weights)) * np.sqrt(weights))\n\n\n\n\n\n","category":"method"}]
}
