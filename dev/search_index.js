var documenterSearchIndex = {"docs":
[{"location":"api/#Base-Functions","page":"Important Functions","title":"Base Functions","text":"","category":"section"},{"location":"api/","page":"Important Functions","title":"Important Functions","text":"Modules = [JML_XAI_Project]","category":"page"},{"location":"api/#JML_XAI_Project.LIME","page":"Important Functions","title":"JML_XAI_Project.LIME","text":"struct LIME{M} <: AbstractXAIMethod\n\nThe LIME (Local Interpretable Model-agnostic Explanations) struct is used to create an instance of the LIME method for explainable AI (XAI). This method provides local explanations for the predictions of any machine learning model by approximating the model's behavior in the vicinity of a specific input.\n\nFields\n\nmodel::M: The machine learning model to be explained. The model should be callable with an input to produce an output.\n\n\n\n\n\n","category":"type"},{"location":"api/#JML_XAI_Project.data_labels","page":"Important Functions","title":"JML_XAI_Project.data_labels","text":"Generates perturbed versions of a given image by turning superpixels on or off,using a specified  segmentation map. It then predicts the class probabilities for these perturbed images using a provided  classifier function. The function returns a tuple containing the binary matrix of perturbed images (data)  and their corresponding prediction probabilities (labels). This is useful for techniques like LIME to  understand and explain model predictions locally.\n\n\n\n\n\n","category":"function"},{"location":"api/#JML_XAI_Project.default_segmentation_function-Tuple{String}","page":"Important Functions","title":"JML_XAI_Project.default_segmentation_function","text":"return image segmantation function, if no function was passed originally based on Scikit-Image implementation julia adaptations:\n\nquickshift\n\npackage: ??? (docs: ???)\nexplaination: ???\npython packages can be used in julia, it's therefore possible to use the scikit-image library if desired\n\nslic\n\ncode: https://github.com/Cuda-Chen/SLIC.jl/tree/master (docs: NOT EVEN AN INOFFICIAL PACKAGE)\ncode seems to work, but spelling mistakes in the original and takes forever\nexplaination: https://cuda-chen.github.io/image%20processing/2020/07/29/slic-in-julia.html\n\nfelzenszwalb\n\npackage: ImageSegmentation (docs: https://juliaimages.org/v0.21/imagesegmentation/)\nexplaination: https://www.analyticsvidhya.com/blog/2021/05/image-segmentation-with-felzenszwalbs-algorithm/\n\ncomparision: https://scikit-image.org/docs/stable/autoexamples/segmentation/plotsegmentations.html\n\nArgs:     algotype: string, segmentation algorithm among the following:         'quickshift', 'slic', 'felzenszwalb'     targetparams: dict, algorithm parameters (valid model paramters         as define in Scikit-Image documentation)\n\n\n\n\n\n","category":"method"},{"location":"api/#JML_XAI_Project.euclidian_distance-Tuple{Any, Any}","page":"Important Functions","title":"JML_XAI_Project.euclidian_distance","text":"calculates the euclidian distance between each column vector in input matrix A and the column vectors in input matrix B\n\nArgs:     A:  matrix (m,n)     B:  matrix (m,n) or (1,n) Returns:     distance: 1-d array of distances\n\n\n\n\n\n","category":"method"},{"location":"api/#JML_XAI_Project.explain_instance","page":"Important Functions","title":"JML_XAI_Project.explain_instance","text":"Generates explanations for a prediction.\n\nFirst, we generate neighborhood data by randomly perturbing features from the instance (see __datainverse). We then learn locally weighted linear models on this neighborhood data to explain each of the classes in an interpretable way (see limebase.py).\n\nArgs:     image: 3 dimension RGB image. If this is only two dimensional,         we will assume it's a grayscale image and call gray2rgb.     classifierfn: classifier prediction probability function, which         takes a numpy array and outputs prediction probabilities.  For         ScikitClassifiers , this is classifier.predictproba.     labels: iterable with labels to be explained.     hidecolor: If not None, will hide superpixels with this color.         Otherwise, use the mean pixel color of the image.     toplabels: if not None, ignore labels and produce explanations for         the K labels with highest prediction probabilities, where K is         this parameter.     numfeatures: maximum number of features present in explanation     numsamples: size of the neighborhood to learn the linear model     batchsize: batch size for model predictions     distancemetric: the distance metric to use for weights.     modelregressor: sklearn regressor to use in explanation. Defaults     to Ridge regression in LimeBase. Must have modelregressor.coef_     and 'sampleweight' as a parameter to modelregressor.fit()     segmentationfn: SegmentationAlgorithm, wrapped skimage     segmentation function     randomseed: integer used as random seed for the segmentation         algorithm. If None, a random integer, between 0 and 1000,         will be generated using the internal random number generator.\n\nReturns:     An ImageExplanation object (see lime_image.py) with the corresponding     explanations.\n\n\n\n\n\n","category":"function"},{"location":"api/#JML_XAI_Project.explain_instance_with_data","page":"Important Functions","title":"JML_XAI_Project.explain_instance_with_data","text":"Takes perturbed data, labels and distances, returns explanation.\n\nParameters\n\nneighborhood_data: perturbed data\nneighborhood_labels: corresponding perturbed labels. should have as many columns as the number of possible labels.\ndistances: distances to original data point.\nkernel_fn: (similiarity) kernel function that transforms an array of distances into an array of proximity values (floats)\nlabel: label for which we want an explanation\nnum_features: maximum number of features in explanation\nmodel_regressor: sklearn regressor to use in explanation. Defaults to Ridge regression if None. Must have modelregressor.coef and 'sampleweight' as a parameter to modelregressor.fit()\n\n\n\n\n\n","category":"function"},{"location":"api/#JML_XAI_Project.feature_selection-Tuple{Any, Any, Any}","page":"Important Functions","title":"JML_XAI_Project.feature_selection","text":"feature_selection(X::Matrix, y::Vector, max_feat::Int) -> ReturnType\n\nSelects features for the model using LARS with Lasso [https://tibshirani.su.domains/ftp/lars.pdf] s.t. len(selectedfeatures) <= maxfeat Use LARS package: https://github.com/simonster/LARS.jl\n\nPython reference: nonzero = range(weighteddata.shape[1]) coefs = generatelarspath(X, y) for i in range(len(coefs.T) - 1, 0, -1):     nonzero = coefs.T[i].nonzero()[0]     if len(nonzero) <= numfeatures:         return nonzero\n\nParameters\n\nX: weighted feature\ny: weighted labels\n\nReturns\n\nindices of selected features\n\n\n\n\n\n","category":"method"},{"location":"api/#JML_XAI_Project.sample_data-Tuple{Any, Any}","page":"Important Functions","title":"JML_XAI_Project.sample_data","text":"sample_data(x0::Vector, x0_pertubed::Vector, H, D, model)\n\nReturns the neighborhood_data (perturbed data, first element is the original data point) by sampling around x0  and evaluate the model to generate the corresponding perturbed labels.\n\nCitation from Paper [https://arxiv.org/pdf/1602.04938]: We sample instances around x0pertubed by drawing nonzero elements of x0pertubed uniformly at random (where the number of such draws is also uniformly sampled). We sample instances both in the vicinity of x0 and far away from x (measured by the distance metric).\n\nParameters\n\nx0: original input\nx0_pertubed: interpretable representation of original input\nH: interpretable representation mapping function, s.t. h(x0_pertubed) = x0\nD: distance metric which calculates the distance of two points in the origial, non-interpretable space\nmodel: model which works on the non-interpretable original input\n\nReturns\n\nneighborhood_data: sampled perturbed data (first element is x0_pertubed)\nneighborhood_labels: corresponding perturbed calculated by the model and mapping function H\ndistances: distances of each sampled point to original data point calculated using the distance metric D and mapping function H\n\n\n\n\n\n","category":"method"},{"location":"api/#JML_XAI_Project.train_ridge_regressor-Tuple{Any, Any}","page":"Important Functions","title":"JML_XAI_Project.train_ridge_regressor","text":"trainridgeregressor(X::Matrix, y::Vector, weights::Vector)\n\nReturns the trained simplified linear model using ridge regression: model = Ridge(alpha=1, fitintercept=True, randomstate=self.randomstate) model.fit(X,y, sampleweight=weights) return model\n\n\n\n\n\n","category":"method"},{"location":"api/#JML_XAI_Project.weighted_data-Tuple{Any, Any, Any}","page":"Important Functions","title":"JML_XAI_Project.weighted_data","text":"normalize_data(X::Matrix, y::Vector, weights::Vector)\n\nReturns the weight normalization of X (data) and y (label) using the weight vector y. Xnorm = ((X - np.average(X, axis=0, weights=weights)) * np.sqrt(weights[:, np.newaxis])) Ynorm = ((y - np.average(y, weights=weights)) * np.sqrt(weights))\n\n\n\n\n\n","category":"method"},{"location":"lime/#LIME","page":"Lime","title":"LIME","text":"","category":"section"},{"location":"lime/","page":"Lime","title":"Lime","text":"For the example, we load an image from the imagenet-sample-images repository.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"using ExplainableAI\nusing Flux\nusing Metalhead: ResNet\ninclude(\"jlFiles/Lime.jl\")\nusing CSV\nusing DataFrames\nusing Images\n\nimg = load(\"jlFiles/n01742172_boa_constrictor.JPEG\")","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"The image is then pre-processed.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"img = permutedims(channelview(img),(3,2,1))\nimg = reshape(img, size(img)..., 1)\ninput = Float32.(img)","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"The next step is to initialize a pre-trained ResNet model and apply LIME to it.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"model = ResNet(18; pretrain = true);\nmodel = model.layers;\nanalyzer = LIME(model);\nexpl = analyze(input, analyzer);","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"The generated explanation can now be displayed as a heat map","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"using VisionHeatmaps\nheatmap(expl.val)","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"To find out the generated corresponding label of the image, we output the number of the label, which can be looked up in the linked text file.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"print(\"Label: \", argmax(expl.output[:,1]) - 1)","category":"page"},{"location":"shap/#SHAP","page":"SHAP","title":"SHAP","text":"","category":"section"},{"location":"shap/","page":"SHAP","title":"SHAP","text":"...to be implemented","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = JML_XAI_Project","category":"page"},{"location":"#JML*XAI*Project-LIME-and-SHAP-for-Julia","page":"Home","title":"JMLXAIProject - LIME and SHAP for Julia","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package implements the explainable AI methods LIME and SHAP using XAIBase.jl. LIME and SHAP are model-agnostic explainable AI methods, so they can be used to explain any model. The JMLXAIproject package provides explanations for image inputs and visualizes them as heatmaps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To use the package please add the following code to your environment","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/e-strauss/JML_XAI_Project.jl\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Documentation for JMLXAIProject.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
