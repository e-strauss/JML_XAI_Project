var documenterSearchIndex = {"docs":
[{"location":"lime/#LIME","page":"Lime","title":"LIME","text":"","category":"section"},{"location":"lime/","page":"Lime","title":"Lime","text":"Because LIME is a \"Local Interpretable Model-agnostic Explanations\" (LIME) you can use it for any model. In addition to the model to be explained, you need a specific input x.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"For our example we use a pre-trained LeNet5 model (model.bson) and a data point of the MNIST dataset for x.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"using ExplainableAI\nusing Flux\nusing BSON\nusing JML_XAI_Project\nusing CSV\nusing DataFrames\nusing XAIBase\nusing Images\n\n#our input x\ndf = CSV.read(\"../MNIST_input_9.csv\", DataFrame)\nx = Matrix(df)\ny = 9\n\ninput = reshape(x, 28, 28, 1, :);\ninput_rgb = repeat(input, 1, 1, 3, 1)\n\n#our model\nmodel = BSON.load(\"../model.bson\", @__MODULE__)[:model]\n","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"Now we are using the XAIBase template to generate an explanaition","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"struct LIME{M} <: AbstractXAIMethod \n    model::M    \nend\n\nfunction (method::LIME)(input, output_selector::AbstractOutputSelector)\n    output = method.model(input)\n    output_selection = output_selector(output)\n\n    val = rand(size(input)...) #it doesn't implement LIME yet\n    extras = nothing  # TODO: optionally add additional information using a named tuple\n    return Explanation(val, output, output_selection, :MyMethod, :attribution, extras)\nend","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"In the next step we call the XAIBase's analyze function to compute the LIME explanation.","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"analyzer = LIME(model)\nexpl = analyze(input, analyzer);","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"To visualize the explanaition we create a heatmap","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"using VisionHeatmaps\nheatmap(expl.val)","category":"page"},{"location":"lime/","page":"Lime","title":"Lime","text":"note: Note\nAs you can see, the heatmap is quite noisy. This is because the XAIBase tamplate is still generating a random output. We still have to implement the LIME algoithm. But if you want to have a first impression of the LIME code structure, have a look at our source code. ","category":"page"},{"location":"shap/#SHAP","page":"SHAP","title":"SHAP","text":"","category":"section"},{"location":"shap/","page":"SHAP","title":"SHAP","text":"...to be implemented","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = JML_XAI_Project","category":"page"},{"location":"#JML*XAI*Project-LIME-and-SHAP-for-Julia","page":"Home","title":"JMLXAIProject - LIME and SHAP for Julia","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package implements the explainable AI methods LIME and SHAP using XAIBase.jl. JMLXAIproject provides explanations for image and text input and is visualized as a heatmap.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To use the package please add the following code to your environment","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/e-strauss/JML_XAI_Project.jl\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Documentation for JMLXAIProject.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [JML_XAI_Project]","category":"page"},{"location":"#JML_XAI_Project.data_labels","page":"Home","title":"JML_XAI_Project.data_labels","text":"Generates perturbed versions of a given image by turning superpixels on or off,using a specified  segmentation map. It then predicts the class probabilities for these perturbed images using a provided  classifier function. The function returns a tuple containing the binary matrix of perturbed images (data)  and their corresponding prediction probabilities (labels). This is useful for techniques like LIME to  understand and explain model predictions locally.\n\n\n\n\n\n","category":"function"},{"location":"#JML_XAI_Project.default_segmentation_function-Tuple{String}","page":"Home","title":"JML_XAI_Project.default_segmentation_function","text":"return image segmantation function, if no function was passed originally based on Scikit-Image implementation julia adaptations:\n\nquickshift\n\npackage: ??? (docs: ???)\nexplaination: ???\npython packages can be used in julia, it's therefore possible to use the scikit-image library if desired\n\nslic\n\ncode: https://github.com/Cuda-Chen/SLIC.jl/tree/master (docs: NOT EVEN AN INOFFICIAL PACKAGE)\ncode seems to work, but spelling mistakes in the original and takes forever\nexplaination: https://cuda-chen.github.io/image%20processing/2020/07/29/slic-in-julia.html\n\nfelzenszwalb\n\npackage: ImageSegmentation (docs: https://juliaimages.org/v0.21/imagesegmentation/)\nexplaination: https://www.analyticsvidhya.com/blog/2021/05/image-segmentation-with-felzenszwalbs-algorithm/\n\ncomparision: https://scikit-image.org/docs/stable/autoexamples/segmentation/plotsegmentations.html\n\nArgs:     algotype: string, segmentation algorithm among the following:         'quickshift', 'slic', 'felzenszwalb'     targetparams: dict, algorithm parameters (valid model paramters         as define in Scikit-Image documentation)\n\n\n\n\n\n","category":"method"},{"location":"#JML_XAI_Project.euclidian_distance-Tuple{Any, Any}","page":"Home","title":"JML_XAI_Project.euclidian_distance","text":"calculates the euclidian distance between each column vector in input matrix A and the column vectors in input matrix B\n\nArgs:     A:  matrix (m,n)     B:  matrix (m,n) or (1,n) Returns:     distance: 1-d array of distances\n\n\n\n\n\n","category":"method"},{"location":"#JML_XAI_Project.explain_instance","page":"Home","title":"JML_XAI_Project.explain_instance","text":"Generates explanations for a prediction.\n\nFirst, we generate neighborhood data by randomly perturbing features from the instance (see __datainverse). We then learn locally weighted linear models on this neighborhood data to explain each of the classes in an interpretable way (see limebase.py).\n\nArgs:     image: 3 dimension RGB image. If this is only two dimensional,         we will assume it's a grayscale image and call gray2rgb.     classifierfn: classifier prediction probability function, which         takes a numpy array and outputs prediction probabilities.  For         ScikitClassifiers , this is classifier.predictproba.     labels: iterable with labels to be explained.     hidecolor: If not None, will hide superpixels with this color.         Otherwise, use the mean pixel color of the image.     toplabels: if not None, ignore labels and produce explanations for         the K labels with highest prediction probabilities, where K is         this parameter.     numfeatures: maximum number of features present in explanation     numsamples: size of the neighborhood to learn the linear model     batchsize: batch size for model predictions     distancemetric: the distance metric to use for weights.     modelregressor: sklearn regressor to use in explanation. Defaults     to Ridge regression in LimeBase. Must have modelregressor.coef_     and 'sampleweight' as a parameter to modelregressor.fit()     segmentationfn: SegmentationAlgorithm, wrapped skimage     segmentation function     randomseed: integer used as random seed for the segmentation         algorithm. If None, a random integer, between 0 and 1000,         will be generated using the internal random number generator.\n\nReturns:     An ImageExplanation object (see lime_image.py) with the corresponding     explanations.\n\n\n\n\n\n","category":"function"}]
}
